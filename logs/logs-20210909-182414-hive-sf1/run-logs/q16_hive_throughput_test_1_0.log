Additional local hive settings found. Adding /jagadesh/hadoop_benchmark_tools/TPCx-BB-master/engines/hive/queries/q16/engineLocalSettings.sql to hive init.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/jagadesh/hive/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/jagadesh/hadoop/hadoop-3.3.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive Session ID = 26fab8d2-e5f6-4917-88a9-295f95c3516b

Logging initialized using configuration in jar:file:/jagadesh/hive/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
Loading class `com.mysql.jdbc.Driver'. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver'. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.
Hive Session ID = 55ec8cf7-7297-4281-bf7f-958dcaf148a7
hive.execution.engine=mr
hive.cbo.enable=true
hive.stats.fetch.partition.stats is undefined
hive.script.operator.truncate.env=false
hive.compute.query.using.stats=true
hive.vectorized.execution.enabled=true
hive.vectorized.execution.reduce.enabled=true
hive.stats.autogather=true
mapreduce.input.fileinputformat.split.minsize=1
mapreduce.input.fileinputformat.split.maxsize=256000000
hive.exec.reducers.bytes.per.reducer=256000000
hive.exec.reducers.max=1009
hive.exec.parallel=true
hive.exec.parallel.thread.number=8
hive.exec.compress.intermediate=false
hive.exec.compress.output=false
mapred.map.output.compression.codec=org.apache.hadoop.io.compress.DefaultCodec
mapred.output.compression.codec=org.apache.hadoop.io.compress.DefaultCodec
hive.default.fileformat=TEXTFILE
hive.auto.convert.sortmerge.join=true
hive.auto.convert.sortmerge.join.noconditionaltask is undefined
hive.optimize.bucketmapjoin=false
hive.optimize.bucketmapjoin.sortedmerge=false
hive.auto.convert.join.noconditionaltask.size=10000000
hive.auto.convert.join=true
hive.optimize.mapjoin.mapreduce is undefined
hive.mapred.local.mem=0
hive.mapjoin.smalltable.filesize=25000000
hive.mapjoin.localtask.max.memory.usage=0.9
hive.optimize.skewjoin=false
hive.optimize.skewjoin.compiletime=false
hive.optimize.ppd=true
hive.optimize.ppd.storage=true
hive.ppd.recognizetransivity=true
hive.optimize.index.filter=false
hive.optimize.sampling.orderby=false
hive.optimize.sampling.orderby.number=1000
hive.optimize.sampling.orderby.percent=0.1
bigbench.hive.optimize.sampling.orderby=true
bigbench.hive.optimize.sampling.orderby.number=20000
bigbench.hive.optimize.sampling.orderby.percent=0.1
hive.groupby.skewindata=false
hive.exec.submit.local.task.via.child=true
hive.exec.compress.output=false
OK
Time taken: 0.072 seconds
OK
Time taken: 0.443 seconds
No Stats for bigbench@web_sales, Columns: ws_warehouse_sk, ws_order_number, ws_item_sk, ws_sold_date_sk, ws_sales_price
No Stats for bigbench@web_returns, Columns: wr_order_number, wr_refunded_cash, wr_item_sk
No Stats for bigbench@item, Columns: i_item_id, i_item_sk
No Stats for bigbench@warehouse, Columns: w_state, w_warehouse_sk
No Stats for bigbench@date_dim, Columns: d_date, d_date_sk
Query ID = odoo_20210909182127_4bcefced-3dbd-49ce-abf7-7aff796b81c9
Total jobs = 3

SLF4J: Found binding in [jar:file:/jagadesh/hive/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/jagadesh/hadoop/hadoop-3.3.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
2021-09-09 18:21:36	Dump the side-table for tag: 1 with group count: 17820 into file: file:/tmp/odoo/26fab8d2-e5f6-4917-88a9-295f95c3516b/hive_2021-09-09_18-21-27_182_5530801907708627277-1/-local-10008/HashTable-Stage-5/MapJoin-mapfile01--.hashtable
2021-09-09 18:21:36	Uploaded 1 File to: file:/tmp/odoo/26fab8d2-e5f6-4917-88a9-295f95c3516b/hive_2021-09-09_18-21-27_182_5530801907708627277-1/-local-10008/HashTable-Stage-5/MapJoin-mapfile01--.hashtable (680339 bytes)
2021-09-09 18:21:36	Dump the side-table for tag: 1 with group count: 61 into file: file:/tmp/odoo/26fab8d2-e5f6-4917-88a9-295f95c3516b/hive_2021-09-09_18-21-27_182_5530801907708627277-1/-local-10008/HashTable-Stage-5/MapJoin-mapfile11--.hashtable
2021-09-09 18:21:36	Uploaded 1 File to: file:/tmp/odoo/26fab8d2-e5f6-4917-88a9-295f95c3516b/hive_2021-09-09_18-21-27_182_5530801907708627277-1/-local-10008/HashTable-Stage-5/MapJoin-mapfile11--.hashtable (2220 bytes)
2021-09-09 18:21:36	Dump the side-table for tag: 1 with group count: 5 into file: file:/tmp/odoo/26fab8d2-e5f6-4917-88a9-295f95c3516b/hive_2021-09-09_18-21-27_182_5530801907708627277-1/-local-10008/HashTable-Stage-5/MapJoin-mapfile21--.hashtable2021-09-09 18:21:36	Uploaded 1 File to: file:/tmp/odoo/26fab8d2-e5f6-4917-88a9-295f95c3516b/hive_2021-09-09_18-21-27_182_5530801907708627277-1/-local-10008/HashTable-Stage-5/MapJoin-mapfile21--.hashtable (370 bytes)
2021-09-09 18:21:36	Dump the side-table for tag: 1 with group count: 38337 into file: file:/tmp/odoo/26fab8d2-e5f6-4917-88a9-295f95c3516b/hive_2021-09-09_18-21-27_182_5530801907708627277-1/-local-10008/HashTable-Stage-5/MapJoin-mapfile31--.hashtable
2021-09-09 18:21:36	Uploaded 1 File to: file:/tmp/odoo/26fab8d2-e5f6-4917-88a9-295f95c3516b/hive_2021-09-09_18-21-27_182_5530801907708627277-1/-local-10008/HashTable-Stage-5/MapJoin-mapfile31--.hashtable (1102220 bytes)
2021-09-09 18:21:36	End of local task; Time Taken: 1.865 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 1 out of 3
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1631181757971_0309, Tracking URL = http://odoo:8088/proxy/application_1631181757971_0309/
Kill Command = /jagadesh/hadoop/hadoop-3.3.0/bin/mapred job  -kill job_1631181757971_0309
Hadoop job information for Stage-5: number of mappers: 1; number of reducers: 1
2021-09-09 18:21:43,494 Stage-5 map = 0%,  reduce = 0%
2021-09-09 18:21:50,709 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 6.16 sec
2021-09-09 18:21:55,839 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 9.11 sec
MapReduce Total cumulative CPU time: 9 seconds 110 msec
Ended Job = job_1631181757971_0309
Launching Job 2 out of 3
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1631181757971_0310, Tracking URL = http://odoo:8088/proxy/application_1631181757971_0310/
Kill Command = /jagadesh/hadoop/hadoop-3.3.0/bin/mapred job  -kill job_1631181757971_0310
Hadoop job information for Stage-6: number of mappers: 1; number of reducers: 1
2021-09-09 18:22:07,378 Stage-6 map = 0%,  reduce = 0%
2021-09-09 18:22:12,516 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 1.9 sec
2021-09-09 18:22:17,669 Stage-6 map = 100%,  reduce = 100%, Cumulative CPU 4.76 sec
MapReduce Total cumulative CPU time: 4 seconds 760 msec
Ended Job = job_1631181757971_0310
Launching Job 3 out of 3
Loading data to table bigbench.q16_hive_throughput_test_1_0_result
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1631181757971_0311, Tracking URL = http://odoo:8088/proxy/application_1631181757971_0311/
Kill Command = /jagadesh/hadoop/hadoop-3.3.0/bin/mapred job  -kill job_1631181757971_0311
Hadoop job information for Stage-8: number of mappers: 1; number of reducers: 1
2021-09-09 18:22:29,408 Stage-8 map = 0%,  reduce = 0%
2021-09-09 18:22:33,506 Stage-8 map = 100%,  reduce = 0%, Cumulative CPU 1.3 sec
2021-09-09 18:22:38,654 Stage-8 map = 100%,  reduce = 100%, Cumulative CPU 3.11 sec
MapReduce Total cumulative CPU time: 3 seconds 110 msec
Ended Job = job_1631181757971_0311
MapReduce Jobs Launched: 
Stage-Stage-5: Map: 1  Reduce: 1   Cumulative CPU: 9.11 sec   HDFS Read: 3152268 HDFS Write: 581363 SUCCESS
Stage-Stage-6: Map: 1  Reduce: 1   Cumulative CPU: 4.76 sec   HDFS Read: 594094 HDFS Write: 4277 SUCCESS
Stage-Stage-8: Map: 1  Reduce: 1   Cumulative CPU: 3.11 sec   HDFS Read: 14069 HDFS Write: 1336 SUCCESS
Total MapReduce CPU Time Spent: 16 seconds 980 msec
OK
Time taken: 74.761 seconds
======= q16_hive_throughput_test_1_0 time =======
Start timestamp: 2021/09/09:18:21:18 1631191878
Stop  timestamp: 2021/09/09:18:22:42 1631191962
Duration:  0h 1m 24s
q16_hive_throughput_test_1_0 SUCCESS exit code: 0 
----- result -----
HAS_RESULT  bytes: 3124
to display: hadoop fs -cat /user/odoo/benchmarks/bigbench/queryResults/q16_hive_throughput_test_1_0_result/*
----- logs -----
time&status: /jagadesh/hadoop_benchmark_tools/TPCx-BB-master/logs/times.csv
full log: /jagadesh/hadoop_benchmark_tools/TPCx-BB-master/logs/q16_hive_throughput_test_1_0.log
=========================
Files /jagadesh/hadoop_benchmark_tools/TPCx-BB-master/engines/hive/queries/q16/results/q16-result and /dev/fd/62 differ
Validation of /jagadesh/hadoop_benchmark_tools/TPCx-BB-master/engines/hive/queries/q16/results/q16-result failed: Query returned incorrect results
Validation failed: Query results are not OK
