Additional local hive settings found. Adding /jagadesh/hadoop_benchmark_tools/TPCx-BB-master/engines/hive/queries/q24/engineLocalSettings.sql to hive init.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/jagadesh/hive/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/jagadesh/hadoop/hadoop-3.3.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive Session ID = 6a6d33a0-2946-4578-a4f7-fe5b6780b331

Logging initialized using configuration in jar:file:/jagadesh/hive/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
Loading class `com.mysql.jdbc.Driver'. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver'. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.
Hive Session ID = 2979627d-f3ef-4e32-9551-ebf0dd968b9b
hive.execution.engine=mr
hive.cbo.enable=true
hive.stats.fetch.partition.stats is undefined
hive.script.operator.truncate.env=false
hive.compute.query.using.stats=true
hive.vectorized.execution.enabled=true
hive.vectorized.execution.reduce.enabled=true
hive.stats.autogather=true
mapreduce.input.fileinputformat.split.minsize=1
mapreduce.input.fileinputformat.split.maxsize=256000000
hive.exec.reducers.bytes.per.reducer=256000000
hive.exec.reducers.max=1009
hive.exec.parallel=true
hive.exec.parallel.thread.number=8
hive.exec.compress.intermediate=false
hive.exec.compress.output=false
mapred.map.output.compression.codec=org.apache.hadoop.io.compress.DefaultCodec
mapred.output.compression.codec=org.apache.hadoop.io.compress.DefaultCodec
hive.default.fileformat=TEXTFILE
hive.auto.convert.sortmerge.join=true
hive.auto.convert.sortmerge.join.noconditionaltask is undefined
hive.optimize.bucketmapjoin=false
hive.optimize.bucketmapjoin.sortedmerge=false
hive.auto.convert.join.noconditionaltask.size=10000000
hive.auto.convert.join=true
hive.optimize.mapjoin.mapreduce is undefined
hive.mapred.local.mem=0
hive.mapjoin.smalltable.filesize=25000000
hive.mapjoin.localtask.max.memory.usage=0.9
hive.optimize.skewjoin=false
hive.optimize.skewjoin.compiletime=false
hive.optimize.ppd=true
hive.optimize.ppd.storage=true
hive.ppd.recognizetransivity=true
hive.optimize.index.filter=false
hive.optimize.sampling.orderby=false
hive.optimize.sampling.orderby.number=1000
hive.optimize.sampling.orderby.percent=0.1
bigbench.hive.optimize.sampling.orderby=true
bigbench.hive.optimize.sampling.orderby.number=20000
bigbench.hive.optimize.sampling.orderby.percent=0.1
hive.groupby.skewindata=false
hive.exec.submit.local.task.via.child=true
OK
Time taken: 0.077 seconds
Warning: Map Join MAPJOIN[18][bigTable=?] in task 'Stage-2:MAPRED' is a cross product
Query ID = odoo_20210909181830_a1bcc8fe-9d6b-4266-9c7d-40559024798c
Total jobs = 1
2021-09-09 18:18:37	Starting to launch local task to process map join;	maximum memory = 239075328
Execution completed successfully
MapredLocal task succeeded
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1631181757971_0303, Tracking URL = http://odoo:8088/proxy/application_1631181757971_0303/
Kill Command = /jagadesh/hadoop/hadoop-3.3.0/bin/mapred job  -kill job_1631181757971_0303
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2021-09-09 18:18:48,555 Stage-2 map = 0%,  reduce = 0%
2021-09-09 18:18:52,793 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 3.13 sec
2021-09-09 18:18:58,946 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 5.48 sec
MapReduce Total cumulative CPU time: 5 seconds 480 msec
Ended Job = job_1631181757971_0303
Moving data to directory hdfs://127.0.0.1:9000/user/hive/warehouse/bigbench.db/q24_hive_throughput_test_1_0_temp
MapReduce Jobs Launched: 
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 5.48 sec   HDFS Read: 77421 HDFS Write: 275 SUCCESS
Total MapReduce CPU Time Spent: 5 seconds 480 msec
OK
Time taken: 34.461 seconds
hive.exec.compress.output=false
OK
Time taken: 0.021 seconds
OK
Time taken: 0.095 seconds
No Stats for bigbench@web_sales, Columns: ws_item_sk, ws_quantity, ws_sold_date_sk
No Stats for bigbench@q24_hive_throughput_test_1_0_temp, Columns: price_change, imp_start_date, imp_sk, no_days_comp_price, i_item_sk
No Stats for bigbench@store_sales, Columns: ss_sold_date_sk, ss_item_sk, ss_quantity
Query ID = odoo_20210909181904_1f6b24ab-c82e-4b78-8dfc-17a4384bfd23
Total jobs = 7

SLF4J: Found binding in [jar:file:/jagadesh/hive/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/jagadesh/hadoop/hadoop-3.3.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.

SLF4J: Found binding in [jar:file:/jagadesh/hive/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/jagadesh/hadoop/hadoop-3.3.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
2021-09-09 18:19:14	Starting to launch local task to process map join;	maximum memory = 239075328
2021-09-09 18:19:16	Dump the side-table for tag: 1 with group count: 1 into file: file:/tmp/odoo/6a6d33a0-2946-4578-a4f7-fe5b6780b331/hive_2021-09-09_18-19-04_722_2299728179723621693-1/-local-10014/HashTable-Stage-9/MapJoin-mapfile41--.hashtable
2021-09-09 18:19:16	Uploaded 1 File to: file:/tmp/odoo/6a6d33a0-2946-4578-a4f7-fe5b6780b331/hive_2021-09-09_18-19-04_722_2299728179723621693-1/-local-10014/HashTable-Stage-9/MapJoin-mapfile41--.hashtable (376 bytes)
2021-09-09 18:19:16	End of local task; Time Taken: 1.91 sec.
2021-09-09 18:19:16	Uploaded 1 File to: file:/tmp/odoo/6a6d33a0-2946-4578-a4f7-fe5b6780b331/hive_2021-09-09_18-19-04_722_2299728179723621693-1/-local-10012/HashTable-Stage-2/MapJoin-mapfile31--.hashtable (376 bytes)
Execution completed successfully
MapredLocal task succeeded
2021-09-09 18:19:16	End of local task; Time Taken: 1.925 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 1 out of 7
Launching Job 2 out of 7
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1631181757971_0305, Tracking URL = http://odoo:8088/proxy/application_1631181757971_0305/
Kill Command = /jagadesh/hadoop/hadoop-3.3.0/bin/mapred job  -kill job_1631181757971_0305
Starting Job = job_1631181757971_0304, Tracking URL = http://odoo:8088/proxy/application_1631181757971_0304/
Kill Command = /jagadesh/hadoop/hadoop-3.3.0/bin/mapred job  -kill job_1631181757971_0304
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2021-09-09 18:19:21,960 Stage-2 map = 0%,  reduce = 0%
2021-09-09 18:19:28,175 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 3.2 sec
2021-09-09 18:19:33,312 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 5.56 sec
MapReduce Total cumulative CPU time: 5 seconds 560 msec
Ended Job = job_1631181757971_0305
Hadoop job information for Stage-9: number of mappers: 1; number of reducers: 1
2021-09-09 18:19:44,500 Stage-9 map = 0%,  reduce = 0%
2021-09-09 18:19:49,653 Stage-9 map = 100%,  reduce = 0%, Cumulative CPU 3.17 sec
2021-09-09 18:19:54,768 Stage-9 map = 100%,  reduce = 100%, Cumulative CPU 5.35 sec
MapReduce Total cumulative CPU time: 5 seconds 350 msec
Ended Job = job_1631181757971_0304
Stage-16 is filtered out by condition resolver.
Stage-17 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.

SLF4J: Found binding in [jar:file:/jagadesh/hive/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/jagadesh/hadoop/hadoop-3.3.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
2021-09-09 18:20:04	Dump the side-table for tag: 0 with group count: 5 into file: file:/tmp/odoo/6a6d33a0-2946-4578-a4f7-fe5b6780b331/hive_2021-09-09_18-19-04_722_2299728179723621693-1/-local-10010/HashTable-Stage-12/MapJoin-mapfile20--.hashtable
Execution completed successfully
MapredLocal task succeeded
Launching Job 4 out of 7
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1631181757971_0306, Tracking URL = http://odoo:8088/proxy/application_1631181757971_0306/
Kill Command = /jagadesh/hadoop/hadoop-3.3.0/bin/mapred job  -kill job_1631181757971_0306
Hadoop job information for Stage-12: number of mappers: 1; number of reducers: 0
2021-09-09 18:20:13,900 Stage-12 map = 0%,  reduce = 0%
2021-09-09 18:20:19,024 Stage-12 map = 100%,  reduce = 0%, Cumulative CPU 2.11 sec
MapReduce Total cumulative CPU time: 2 seconds 110 msec
Ended Job = job_1631181757971_0306
Launching Job 5 out of 7
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1631181757971_0307, Tracking URL = http://odoo:8088/proxy/application_1631181757971_0307/
Kill Command = /jagadesh/hadoop/hadoop-3.3.0/bin/mapred job  -kill job_1631181757971_0307
Hadoop job information for Stage-4: number of mappers: 1; number of reducers: 1
2021-09-09 18:20:31,095 Stage-4 map = 0%,  reduce = 0%
2021-09-09 18:20:35,203 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 1.31 sec
2021-09-09 18:20:40,327 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 3.83 sec
MapReduce Total cumulative CPU time: 3 seconds 830 msec
Ended Job = job_1631181757971_0307
Loading data to table bigbench.q24_hive_throughput_test_1_0_result
Launching Job 6 out of 7
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1631181757971_0308, Tracking URL = http://odoo:8088/proxy/application_1631181757971_0308/
Kill Command = /jagadesh/hadoop/hadoop-3.3.0/bin/mapred job  -kill job_1631181757971_0308
Hadoop job information for Stage-6: number of mappers: 1; number of reducers: 1
2021-09-09 18:20:51,551 Stage-6 map = 0%,  reduce = 0%
2021-09-09 18:20:56,677 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 1.29 sec
2021-09-09 18:21:00,772 Stage-6 map = 100%,  reduce = 100%, Cumulative CPU 3.04 sec
MapReduce Total cumulative CPU time: 3 seconds 40 msec
Ended Job = job_1631181757971_0308
MapReduce Jobs Launched: 
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 5.56 sec   HDFS Read: 1837032 HDFS Write: 247 SUCCESS
Stage-Stage-9: Map: 1  Reduce: 1   Cumulative CPU: 5.35 sec   HDFS Read: 1842589 HDFS Write: 279 SUCCESS
Stage-Stage-12: Map: 1   Cumulative CPU: 2.11 sec   HDFS Read: 11261 HDFS Write: 124 SUCCESS
Stage-Stage-4: Map: 1  Reduce: 1   Cumulative CPU: 3.83 sec   HDFS Read: 11811 HDFS Write: 297 SUCCESS
Stage-Stage-6: Map: 1  Reduce: 1   Cumulative CPU: 3.04 sec   HDFS Read: 10947 HDFS Write: 188 SUCCESS
Total MapReduce CPU Time Spent: 19 seconds 890 msec
OK
Time taken: 120.403 seconds
OK
Time taken: 0.205 seconds
======= q24_hive_throughput_test_1_0 time =======
Start timestamp: 2021/09/09:18:18:20 1631191700
Stop  timestamp: 2021/09/09:18:21:05 1631191865
Duration:  0h 2m 45s
q24_hive_throughput_test_1_0 SUCCESS exit code: 0 
----- result -----
HAS_RESULT  bytes: 17
to display: hadoop fs -cat /user/odoo/benchmarks/bigbench/queryResults/q24_hive_throughput_test_1_0_result/*
----- logs -----
time&status: /jagadesh/hadoop_benchmark_tools/TPCx-BB-master/logs/times.csv
full log: /jagadesh/hadoop_benchmark_tools/TPCx-BB-master/logs/q24_hive_throughput_test_1_0.log
=========================
Validation of /jagadesh/hadoop_benchmark_tools/TPCx-BB-master/engines/hive/queries/q24/results/q24-result passed: Query returned correct results
Validation passed: Query results are OK
