=========================
q05 Step 1/3: Executing hive queries
tmp output: /user/odoo/benchmarks/bigbench/temp/q05_hive_throughput_test_1_0_temp
=========================
Additional local hive settings found. Adding /jagadesh/hadoop_benchmark_tools/TPCx-BB-master/engines/hive/queries/q05/engineLocalSettings.sql to hive init.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/jagadesh/hive/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/jagadesh/hadoop/hadoop-3.3.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive Session ID = f4a9ab1e-6d9f-4700-8d07-af5e14bed77f

Logging initialized using configuration in jar:file:/jagadesh/hive/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
Loading class `com.mysql.jdbc.Driver'. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver'. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.
Hive Session ID = b02b4405-d60c-4b58-9973-e1a5bd227b1b
hive.execution.engine=mr
hive.cbo.enable=true
hive.stats.fetch.partition.stats is undefined
hive.script.operator.truncate.env=false
hive.compute.query.using.stats=true
hive.vectorized.execution.enabled=true
hive.vectorized.execution.reduce.enabled=true
hive.stats.autogather=true
mapreduce.input.fileinputformat.split.minsize=1
mapreduce.input.fileinputformat.split.maxsize=256000000
hive.exec.reducers.bytes.per.reducer=256000000
hive.exec.reducers.max=1009
hive.exec.parallel=true
hive.exec.parallel.thread.number=8
hive.exec.compress.intermediate=false
hive.exec.compress.output=false
mapred.map.output.compression.codec=org.apache.hadoop.io.compress.DefaultCodec
mapred.output.compression.codec=org.apache.hadoop.io.compress.DefaultCodec
hive.default.fileformat=TEXTFILE
hive.auto.convert.sortmerge.join=true
hive.auto.convert.sortmerge.join.noconditionaltask is undefined
hive.optimize.bucketmapjoin=false
hive.optimize.bucketmapjoin.sortedmerge=false
hive.auto.convert.join.noconditionaltask.size=10000000
hive.auto.convert.join=true
hive.optimize.mapjoin.mapreduce is undefined
hive.mapred.local.mem=0
hive.mapjoin.smalltable.filesize=25000000
hive.mapjoin.localtask.max.memory.usage=0.9
hive.optimize.skewjoin=false
hive.optimize.skewjoin.compiletime=false
hive.optimize.ppd=true
hive.optimize.ppd.storage=true
hive.ppd.recognizetransivity=true
hive.optimize.index.filter=false
hive.optimize.sampling.orderby=false
hive.optimize.sampling.orderby.number=1000
hive.optimize.sampling.orderby.percent=0.1
bigbench.hive.optimize.sampling.orderby=true
bigbench.hive.optimize.sampling.orderby.number=20000
bigbench.hive.optimize.sampling.orderby.percent=0.1
hive.groupby.skewindata=false
hive.exec.submit.local.task.via.child=true
OK
Time taken: 0.073 seconds
OK
Time taken: 0.421 seconds
No Stats for bigbench@web_clickstreams, Columns: wcs_item_sk, wcs_user_sk
No Stats for bigbench@item, Columns: i_category, i_category_id, i_item_sk
No Stats for bigbench@customer, Columns: c_customer_sk, c_current_cdemo_sk
No Stats for bigbench@customer_demographics, Columns: cd_demo_sk, cd_education_status, cd_gender
Query ID = odoo_20210909174600_29064036-7f40-4582-ab3d-83fe9070de65
Total jobs = 6

SLF4J: Found binding in [jar:file:/jagadesh/hive/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/jagadesh/hadoop/hadoop-3.3.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
SLF4J: Found binding in [jar:file:/jagadesh/hadoop/hadoop-3.3.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
2021-09-09 17:46:08	Starting to launch local task to process map join;	maximum memory = 239075328
2021-09-09 17:46:08	Starting to launch local task to process map join;	maximum memory = 239075328
2021-09-09 17:46:11	Dump the side-table for tag: 1 with group count: 17820 into file: file:/tmp/odoo/f4a9ab1e-6d9f-4700-8d07-af5e14bed77f/hive_2021-09-09_17-46-00_247_6641585216108189968-1/-local-10012/HashTable-Stage-7/MapJoin-mapfile31--.hashtable
2021-09-09 17:46:11	Dump the side-table for tag: 1 with group count: 96438 into file: file:/tmp/odoo/f4a9ab1e-6d9f-4700-8d07-af5e14bed77f/hive_2021-09-09_17-46-00_247_6641585216108189968-1/-local-10010/HashTable-Stage-12/MapJoin-mapfile21--.hashtable
2021-09-09 17:46:11	Uploaded 1 File to: file:/tmp/odoo/f4a9ab1e-6d9f-4700-8d07-af5e14bed77f/hive_2021-09-09_17-46-00_247_6641585216108189968-1/-local-10010/HashTable-Stage-12/MapJoin-mapfile21--.hashtable (2473358 bytes)
2021-09-09 17:46:11	End of local task; Time Taken: 3.246 sec.
2021-09-09 17:46:11	Uploaded 1 File to: file:/tmp/odoo/f4a9ab1e-6d9f-4700-8d07-af5e14bed77f/hive_2021-09-09_17-46-00_247_6641585216108189968-1/-local-10012/HashTable-Stage-7/MapJoin-mapfile31--.hashtable (544168 bytes)
Execution completed successfully
MapredLocal task succeeded
Execution completed successfully
MapredLocal task succeeded
Launching Job 1 out of 6
Launching Job 2 out of 6
Number of reduce tasks is set to 0 since there's no reduce operator
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1631181757971_0252, Tracking URL = http://odoo:8088/proxy/application_1631181757971_0252/
Starting Job = job_1631181757971_0251, Tracking URL = http://odoo:8088/proxy/application_1631181757971_0251/
Kill Command = /jagadesh/hadoop/hadoop-3.3.0/bin/mapred job  -kill job_1631181757971_0252
Kill Command = /jagadesh/hadoop/hadoop-3.3.0/bin/mapred job  -kill job_1631181757971_0251
Hadoop job information for Stage-12: number of mappers: 1; number of reducers: 0
2021-09-09 17:46:30,483 Stage-12 map = 100%,  reduce = 0%
Ended Job = job_1631181757971_0252 with errors
Error during job, obtaining debugging information...
FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
java.io.IOException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:345)
	at org.apache.hadoop.mapred.ClientServiceDelegate.getJobStatus(ClientServiceDelegate.java:430)
	at org.apache.hadoop.mapred.YARNRunner.getJobStatus(YARNRunner.java:872)
	at org.apache.hadoop.mapreduce.Job$1.run(Job.java:333)
	at org.apache.hadoop.mapreduce.Job$1.run(Job.java:330)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:330)
	at org.apache.hadoop.mapreduce.Job.getJobState(Job.java:362)
	at org.apache.hadoop.mapred.JobClient$NetworkedJob.getJobState(JobClient.java:300)
	at org.apache.hadoop.hive.ql.exec.mr.HadoopJobExecHelper.progress(HadoopJobExecHelper.java:251)
	at org.apache.hadoop.hive.ql.exec.mr.HadoopJobExecHelper.progress(HadoopJobExecHelper.java:559)
	at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:433)
	at org.apache.hadoop.hive.ql.exec.mr.MapRedTask.execute(MapRedTask.java:149)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:205)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:97)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.run(TaskRunner.java:76)
Caused by: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:837)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:753)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1566)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy88.getJobReport(Unknown Source)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getJobReport(MRClientProtocolPBClientImpl.java:135)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:326)
	... 17 more
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:533)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:699)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:812)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:413)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1636)
	at org.apache.hadoop.ipc.Client.call(Client.java:1452)
	... 26 more
Ended Job = job_1631181757971_0251 with exception 'java.io.IOException(java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort)'
MapReduce Jobs Launched: 
Stage-Stage-12: Map: 1   HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
======= q05_hive_throughput_test_1_0 time =======
Start timestamp: 2021/09/09:17:45:51 1631189751
Stop  timestamp: 2021/09/09:17:47:20 1631189840
Duration:  0h 1m 29s
q05_hive_throughput_test_1_0 FAILED exit code: 2 
----- result -----
EMPTY  bytes: 0
to display: hadoop fs -cat /user/odoo/benchmarks/bigbench/queryResults/q05_hive_throughput_test_1_0_result/*
----- logs -----
time&status: /jagadesh/hadoop_benchmark_tools/TPCx-BB-master/logs/times.csv
full log: /jagadesh/hadoop_benchmark_tools/TPCx-BB-master/logs/q05_hive_throughput_test_1_0.log
=========================
cat: `/user/odoo/benchmarks/bigbench/queryResults/q05_hive_throughput_test_1_0_result/*': No such file or directory
Files /jagadesh/hadoop_benchmark_tools/TPCx-BB-master/engines/hive/queries/q05/results/q05-result and /dev/fd/62 differ
Validation of /jagadesh/hadoop_benchmark_tools/TPCx-BB-master/engines/hive/queries/q05/results/q05-result failed: Query returned incorrect results
Validation failed: Query results are not OK
